# zsh-ai Configuration
# Copy this file to .env and set your values

# Provider selection: "anthropic", "gemini", "openai", or "ollama"
ZSH_AI_PROVIDER="openai"

# =============================================================================
# Provider-specific settings
# =============================================================================

# Anthropic settings
# ANTHROPIC_API_KEY="your-anthropic-api-key"
# ZSH_AI_ANTHROPIC_MODEL="claude-haiku-4-5"

# OpenAI settings
# ZSH_AI_OPENAI_URL="https://api.openai.com/v1/chat/completions"
# OPENAI_API_KEY="your-openai-api-key"
# ZSH_AI_OPENAI_MODEL="gpt-4o"

# Gemini settings
# ZSH_AI_GEMINI_MODEL="gemini-2.5-flash"
# GEMINI_API_KEY="your-gemini-api-key"

# Ollama settings (local models)
# ZSH_AI_OLLAMA_MODEL="llama3.2"
# ZSH_AI_OLLAMA_URL="http://localhost:11434"

# =============================================================================
# Advanced settings
# =============================================================================

# Command prefix to trigger AI (default: "# ")
# Examples: "? ", "ai ", ">> "
# ZSH_AI_PREFIX="# "

# Request timeout in seconds (default: 30)
# ZSH_AI_TIMEOUT=30

# Extra kwargs for LLM API calls (JSON format)
# Example: Override temperature, add top_p, etc.
# ZSH_AI_EXTRA_KWARGS='{"temperature": 0.1}'
# ZSH_AI_EXTRA_KWARGS='{"temperature": 0.5, "top_p": 0.9}'

# Language for --e explanation output (default: "EN")
# Examples: "EN" (English), "KO" (Korean), "JA" (Japanese), "ZH" (Chinese)
# ZSH_AI_LANG="EN"
